{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6511948",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1666a2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fef8b6",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b90fd656",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a8e0335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f103c96",
   "metadata": {},
   "source": [
    "## View the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b696aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7        V8        V9  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599  0.098698  0.363787   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803  0.085102 -0.255425   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461  0.247676 -1.514654   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609  0.377436 -1.387024   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941 -0.270533  0.817739   \n",
       "\n",
       "   ...       V21       V22       V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0  ... -0.018307  0.277838 -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n",
       "1  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n",
       "2  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n",
       "3  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n",
       "4  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n",
       "\n",
       "   Class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.width', 100)     # This line of code sets the display width option for pandas dataframes to 100 characters. However, setting the display width option may not be noticeable if your dataframe doesn't have rows with very long strings or if the columns don't have many elements. WHICH IS HAPPENING HERE.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a704b1c1",
   "metadata": {},
   "source": [
    "* Most of the feature's values seems to be normalised.\n",
    "* features are anonymised.\n",
    "* classification type data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e48445",
   "metadata": {},
   "source": [
    "## Dimension of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c5a8b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(284807, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efd1dee",
   "metadata": {},
   "source": [
    "This dimension can help in cases when we see the general info of the dataframe, then we come to know about how many rows in each feature has non null values, so by comparing to total number of rows we get the general idea about rows with null values for that particular feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5259bc02",
   "metadata": {},
   "source": [
    "## Data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4430abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766ac863",
   "metadata": {},
   "source": [
    "* 30 features with float data type and one with integer datatype.\n",
    "* Nan values do not present in the datasey. Because of the Non-Null count and number of rows in teh dataset match.\n",
    "* There are 30 input feature with float datatype and one output feature with int datatype.\n",
    "* Also telling memeory usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340b1732",
   "metadata": {},
   "source": [
    "## Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21a4253f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Time      0\n",
       "V1        0\n",
       "V2        0\n",
       "V3        0\n",
       "V4        0\n",
       "V5        0\n",
       "V6        0\n",
       "V7        0\n",
       "V8        0\n",
       "V9        0\n",
       "V10       0\n",
       "V11       0\n",
       "V12       0\n",
       "V13       0\n",
       "V14       0\n",
       "V15       0\n",
       "V16       0\n",
       "V17       0\n",
       "V18       0\n",
       "V19       0\n",
       "V20       0\n",
       "V21       0\n",
       "V22       0\n",
       "V23       0\n",
       "V24       0\n",
       "V25       0\n",
       "V26       0\n",
       "V27       0\n",
       "V28       0\n",
       "Amount    0\n",
       "Class     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()             # conforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff2d77",
   "metadata": {},
   "source": [
    "* The dataset does not contain any null values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75714c8a",
   "metadata": {},
   "source": [
    "## Statistical Analysis of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd3e65",
   "metadata": {},
   "source": [
    "* `DataFrame.describe()` is used to get the **descriptive statastics**. * Descriptive stataistics summarize the count of values in each column of the data set.\n",
    "* We get mean(), standard deviation, and interquartile ranges **while excluding Nan values**.\n",
    "* However, the `describe()` method deals only with numeric values, not with any categorical values.\n",
    "* The `describe()` method **ignores the columns with categorical values** and displays a summary for the other columns.\n",
    "* To sisplay the categorical values, we need to pass the parameter `include = \"all\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be5b3831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>284807.000000</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>2.848070e+05</td>\n",
       "      <td>284807.000000</td>\n",
       "      <td>284807.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>94813.859575</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>88.349619</td>\n",
       "      <td>0.001727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>47488.145955</td>\n",
       "      <td>1.958696e+00</td>\n",
       "      <td>1.651309e+00</td>\n",
       "      <td>1.516255e+00</td>\n",
       "      <td>1.415869e+00</td>\n",
       "      <td>1.380247e+00</td>\n",
       "      <td>1.332271e+00</td>\n",
       "      <td>1.237094e+00</td>\n",
       "      <td>1.194353e+00</td>\n",
       "      <td>1.098632e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>7.345240e-01</td>\n",
       "      <td>7.257016e-01</td>\n",
       "      <td>6.244603e-01</td>\n",
       "      <td>6.056471e-01</td>\n",
       "      <td>5.212781e-01</td>\n",
       "      <td>4.822270e-01</td>\n",
       "      <td>4.036325e-01</td>\n",
       "      <td>3.300833e-01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.640751e+01</td>\n",
       "      <td>-7.271573e+01</td>\n",
       "      <td>-4.832559e+01</td>\n",
       "      <td>-5.683171e+00</td>\n",
       "      <td>-1.137433e+02</td>\n",
       "      <td>-2.616051e+01</td>\n",
       "      <td>-4.355724e+01</td>\n",
       "      <td>-7.321672e+01</td>\n",
       "      <td>-1.343407e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.483038e+01</td>\n",
       "      <td>-1.093314e+01</td>\n",
       "      <td>-4.480774e+01</td>\n",
       "      <td>-2.836627e+00</td>\n",
       "      <td>-1.029540e+01</td>\n",
       "      <td>-2.604551e+00</td>\n",
       "      <td>-2.256568e+01</td>\n",
       "      <td>-1.543008e+01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54201.500000</td>\n",
       "      <td>-9.203734e-01</td>\n",
       "      <td>-5.985499e-01</td>\n",
       "      <td>-8.903648e-01</td>\n",
       "      <td>-8.486401e-01</td>\n",
       "      <td>-6.915971e-01</td>\n",
       "      <td>-7.682956e-01</td>\n",
       "      <td>-5.540759e-01</td>\n",
       "      <td>-2.086297e-01</td>\n",
       "      <td>-6.430976e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.283949e-01</td>\n",
       "      <td>-5.423504e-01</td>\n",
       "      <td>-1.618463e-01</td>\n",
       "      <td>-3.545861e-01</td>\n",
       "      <td>-3.171451e-01</td>\n",
       "      <td>-3.269839e-01</td>\n",
       "      <td>-7.083953e-02</td>\n",
       "      <td>-5.295979e-02</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>84692.000000</td>\n",
       "      <td>1.810880e-02</td>\n",
       "      <td>6.548556e-02</td>\n",
       "      <td>1.798463e-01</td>\n",
       "      <td>-1.984653e-02</td>\n",
       "      <td>-5.433583e-02</td>\n",
       "      <td>-2.741871e-01</td>\n",
       "      <td>4.010308e-02</td>\n",
       "      <td>2.235804e-02</td>\n",
       "      <td>-5.142873e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.945017e-02</td>\n",
       "      <td>6.781943e-03</td>\n",
       "      <td>-1.119293e-02</td>\n",
       "      <td>4.097606e-02</td>\n",
       "      <td>1.659350e-02</td>\n",
       "      <td>-5.213911e-02</td>\n",
       "      <td>1.342146e-03</td>\n",
       "      <td>1.124383e-02</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>139320.500000</td>\n",
       "      <td>1.315642e+00</td>\n",
       "      <td>8.037239e-01</td>\n",
       "      <td>1.027196e+00</td>\n",
       "      <td>7.433413e-01</td>\n",
       "      <td>6.119264e-01</td>\n",
       "      <td>3.985649e-01</td>\n",
       "      <td>5.704361e-01</td>\n",
       "      <td>3.273459e-01</td>\n",
       "      <td>5.971390e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>1.863772e-01</td>\n",
       "      <td>5.285536e-01</td>\n",
       "      <td>1.476421e-01</td>\n",
       "      <td>4.395266e-01</td>\n",
       "      <td>3.507156e-01</td>\n",
       "      <td>2.409522e-01</td>\n",
       "      <td>9.104512e-02</td>\n",
       "      <td>7.827995e-02</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>172792.000000</td>\n",
       "      <td>2.454930e+00</td>\n",
       "      <td>2.205773e+01</td>\n",
       "      <td>9.382558e+00</td>\n",
       "      <td>1.687534e+01</td>\n",
       "      <td>3.480167e+01</td>\n",
       "      <td>7.330163e+01</td>\n",
       "      <td>1.205895e+02</td>\n",
       "      <td>2.000721e+01</td>\n",
       "      <td>1.559499e+01</td>\n",
       "      <td>...</td>\n",
       "      <td>2.720284e+01</td>\n",
       "      <td>1.050309e+01</td>\n",
       "      <td>2.252841e+01</td>\n",
       "      <td>4.584549e+00</td>\n",
       "      <td>7.519589e+00</td>\n",
       "      <td>3.517346e+00</td>\n",
       "      <td>3.161220e+01</td>\n",
       "      <td>3.384781e+01</td>\n",
       "      <td>25691.160000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Time            V1            V2            V3            V4            V5  \\\n",
       "count  284807.000000  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean    94813.859575  1.168375e-15  3.416908e-16 -1.379537e-15  2.074095e-15  9.604066e-16   \n",
       "std     47488.145955  1.958696e+00  1.651309e+00  1.516255e+00  1.415869e+00  1.380247e+00   \n",
       "min         0.000000 -5.640751e+01 -7.271573e+01 -4.832559e+01 -5.683171e+00 -1.137433e+02   \n",
       "25%     54201.500000 -9.203734e-01 -5.985499e-01 -8.903648e-01 -8.486401e-01 -6.915971e-01   \n",
       "50%     84692.000000  1.810880e-02  6.548556e-02  1.798463e-01 -1.984653e-02 -5.433583e-02   \n",
       "75%    139320.500000  1.315642e+00  8.037239e-01  1.027196e+00  7.433413e-01  6.119264e-01   \n",
       "max    172792.000000  2.454930e+00  2.205773e+01  9.382558e+00  1.687534e+01  3.480167e+01   \n",
       "\n",
       "                 V6            V7            V8            V9  ...           V21           V22  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  ...  2.848070e+05  2.848070e+05   \n",
       "mean   1.487313e-15 -5.556467e-16  1.213481e-16 -2.406331e-15  ...  1.654067e-16 -3.568593e-16   \n",
       "std    1.332271e+00  1.237094e+00  1.194353e+00  1.098632e+00  ...  7.345240e-01  7.257016e-01   \n",
       "min   -2.616051e+01 -4.355724e+01 -7.321672e+01 -1.343407e+01  ... -3.483038e+01 -1.093314e+01   \n",
       "25%   -7.682956e-01 -5.540759e-01 -2.086297e-01 -6.430976e-01  ... -2.283949e-01 -5.423504e-01   \n",
       "50%   -2.741871e-01  4.010308e-02  2.235804e-02 -5.142873e-02  ... -2.945017e-02  6.781943e-03   \n",
       "75%    3.985649e-01  5.704361e-01  3.273459e-01  5.971390e-01  ...  1.863772e-01  5.285536e-01   \n",
       "max    7.330163e+01  1.205895e+02  2.000721e+01  1.559499e+01  ...  2.720284e+01  1.050309e+01   \n",
       "\n",
       "                V23           V24           V25           V26           V27           V28  \\\n",
       "count  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05  2.848070e+05   \n",
       "mean   2.578648e-16  4.473266e-15  5.340915e-16  1.683437e-15 -3.660091e-16 -1.227390e-16   \n",
       "std    6.244603e-01  6.056471e-01  5.212781e-01  4.822270e-01  4.036325e-01  3.300833e-01   \n",
       "min   -4.480774e+01 -2.836627e+00 -1.029540e+01 -2.604551e+00 -2.256568e+01 -1.543008e+01   \n",
       "25%   -1.618463e-01 -3.545861e-01 -3.171451e-01 -3.269839e-01 -7.083953e-02 -5.295979e-02   \n",
       "50%   -1.119293e-02  4.097606e-02  1.659350e-02 -5.213911e-02  1.342146e-03  1.124383e-02   \n",
       "75%    1.476421e-01  4.395266e-01  3.507156e-01  2.409522e-01  9.104512e-02  7.827995e-02   \n",
       "max    2.252841e+01  4.584549e+00  7.519589e+00  3.517346e+00  3.161220e+01  3.384781e+01   \n",
       "\n",
       "              Amount          Class  \n",
       "count  284807.000000  284807.000000  \n",
       "mean       88.349619       0.001727  \n",
       "std       250.120109       0.041527  \n",
       "min         0.000000       0.000000  \n",
       "25%         5.600000       0.000000  \n",
       "50%        22.000000       0.000000  \n",
       "75%        77.165000       0.000000  \n",
       "max     25691.160000       1.000000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2a502b",
   "metadata": {},
   "source": [
    "* Can see that the **mean and the median{the row with `50%` values} are different**, that **means data is skewed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f911a6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.481386e+04</td>\n",
       "      <td>47488.145955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>54201.500000</td>\n",
       "      <td>84692.000000</td>\n",
       "      <td>139320.500000</td>\n",
       "      <td>172792.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V1</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.168375e-15</td>\n",
       "      <td>1.958696</td>\n",
       "      <td>-56.407510</td>\n",
       "      <td>-0.920373</td>\n",
       "      <td>0.018109</td>\n",
       "      <td>1.315642</td>\n",
       "      <td>2.454930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V2</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>3.416908e-16</td>\n",
       "      <td>1.651309</td>\n",
       "      <td>-72.715728</td>\n",
       "      <td>-0.598550</td>\n",
       "      <td>0.065486</td>\n",
       "      <td>0.803724</td>\n",
       "      <td>22.057729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V3</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.379537e-15</td>\n",
       "      <td>1.516255</td>\n",
       "      <td>-48.325589</td>\n",
       "      <td>-0.890365</td>\n",
       "      <td>0.179846</td>\n",
       "      <td>1.027196</td>\n",
       "      <td>9.382558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V4</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.074095e-15</td>\n",
       "      <td>1.415869</td>\n",
       "      <td>-5.683171</td>\n",
       "      <td>-0.848640</td>\n",
       "      <td>-0.019847</td>\n",
       "      <td>0.743341</td>\n",
       "      <td>16.875344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V5</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.604066e-16</td>\n",
       "      <td>1.380247</td>\n",
       "      <td>-113.743307</td>\n",
       "      <td>-0.691597</td>\n",
       "      <td>-0.054336</td>\n",
       "      <td>0.611926</td>\n",
       "      <td>34.801666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V6</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.487313e-15</td>\n",
       "      <td>1.332271</td>\n",
       "      <td>-26.160506</td>\n",
       "      <td>-0.768296</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.398565</td>\n",
       "      <td>73.301626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V7</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-5.556467e-16</td>\n",
       "      <td>1.237094</td>\n",
       "      <td>-43.557242</td>\n",
       "      <td>-0.554076</td>\n",
       "      <td>0.040103</td>\n",
       "      <td>0.570436</td>\n",
       "      <td>120.589494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V8</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.213481e-16</td>\n",
       "      <td>1.194353</td>\n",
       "      <td>-73.216718</td>\n",
       "      <td>-0.208630</td>\n",
       "      <td>0.022358</td>\n",
       "      <td>0.327346</td>\n",
       "      <td>20.007208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V9</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-2.406331e-15</td>\n",
       "      <td>1.098632</td>\n",
       "      <td>-13.434066</td>\n",
       "      <td>-0.643098</td>\n",
       "      <td>-0.051429</td>\n",
       "      <td>0.597139</td>\n",
       "      <td>15.594995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V10</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.239053e-15</td>\n",
       "      <td>1.088850</td>\n",
       "      <td>-24.588262</td>\n",
       "      <td>-0.535426</td>\n",
       "      <td>-0.092917</td>\n",
       "      <td>0.453923</td>\n",
       "      <td>23.745136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V11</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.673327e-15</td>\n",
       "      <td>1.020713</td>\n",
       "      <td>-4.797473</td>\n",
       "      <td>-0.762494</td>\n",
       "      <td>-0.032757</td>\n",
       "      <td>0.739593</td>\n",
       "      <td>12.018913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V12</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.247012e-15</td>\n",
       "      <td>0.999201</td>\n",
       "      <td>-18.683715</td>\n",
       "      <td>-0.405571</td>\n",
       "      <td>0.140033</td>\n",
       "      <td>0.618238</td>\n",
       "      <td>7.848392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V13</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.190001e-16</td>\n",
       "      <td>0.995274</td>\n",
       "      <td>-5.791881</td>\n",
       "      <td>-0.648539</td>\n",
       "      <td>-0.013568</td>\n",
       "      <td>0.662505</td>\n",
       "      <td>7.126883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V14</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.207294e-15</td>\n",
       "      <td>0.958596</td>\n",
       "      <td>-19.214325</td>\n",
       "      <td>-0.425574</td>\n",
       "      <td>0.050601</td>\n",
       "      <td>0.493150</td>\n",
       "      <td>10.526766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V15</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.887456e-15</td>\n",
       "      <td>0.915316</td>\n",
       "      <td>-4.498945</td>\n",
       "      <td>-0.582884</td>\n",
       "      <td>0.048072</td>\n",
       "      <td>0.648821</td>\n",
       "      <td>8.877742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V16</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.437716e-15</td>\n",
       "      <td>0.876253</td>\n",
       "      <td>-14.129855</td>\n",
       "      <td>-0.468037</td>\n",
       "      <td>0.066413</td>\n",
       "      <td>0.523296</td>\n",
       "      <td>17.315112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V17</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.772171e-16</td>\n",
       "      <td>0.849337</td>\n",
       "      <td>-25.162799</td>\n",
       "      <td>-0.483748</td>\n",
       "      <td>-0.065676</td>\n",
       "      <td>0.399675</td>\n",
       "      <td>9.253526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V18</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>9.564149e-16</td>\n",
       "      <td>0.838176</td>\n",
       "      <td>-9.498746</td>\n",
       "      <td>-0.498850</td>\n",
       "      <td>-0.003636</td>\n",
       "      <td>0.500807</td>\n",
       "      <td>5.041069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V19</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.039917e-15</td>\n",
       "      <td>0.814041</td>\n",
       "      <td>-7.213527</td>\n",
       "      <td>-0.456299</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.458949</td>\n",
       "      <td>5.591971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V20</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>6.406204e-16</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>-54.497720</td>\n",
       "      <td>-0.211721</td>\n",
       "      <td>-0.062481</td>\n",
       "      <td>0.133041</td>\n",
       "      <td>39.420904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V21</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.654067e-16</td>\n",
       "      <td>0.734524</td>\n",
       "      <td>-34.830382</td>\n",
       "      <td>-0.228395</td>\n",
       "      <td>-0.029450</td>\n",
       "      <td>0.186377</td>\n",
       "      <td>27.202839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V22</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.568593e-16</td>\n",
       "      <td>0.725702</td>\n",
       "      <td>-10.933144</td>\n",
       "      <td>-0.542350</td>\n",
       "      <td>0.006782</td>\n",
       "      <td>0.528554</td>\n",
       "      <td>10.503090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V23</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>2.578648e-16</td>\n",
       "      <td>0.624460</td>\n",
       "      <td>-44.807735</td>\n",
       "      <td>-0.161846</td>\n",
       "      <td>-0.011193</td>\n",
       "      <td>0.147642</td>\n",
       "      <td>22.528412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V24</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>4.473266e-15</td>\n",
       "      <td>0.605647</td>\n",
       "      <td>-2.836627</td>\n",
       "      <td>-0.354586</td>\n",
       "      <td>0.040976</td>\n",
       "      <td>0.439527</td>\n",
       "      <td>4.584549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V25</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>5.340915e-16</td>\n",
       "      <td>0.521278</td>\n",
       "      <td>-10.295397</td>\n",
       "      <td>-0.317145</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>0.350716</td>\n",
       "      <td>7.519589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V26</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.683437e-15</td>\n",
       "      <td>0.482227</td>\n",
       "      <td>-2.604551</td>\n",
       "      <td>-0.326984</td>\n",
       "      <td>-0.052139</td>\n",
       "      <td>0.240952</td>\n",
       "      <td>3.517346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V27</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-3.660091e-16</td>\n",
       "      <td>0.403632</td>\n",
       "      <td>-22.565679</td>\n",
       "      <td>-0.070840</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>0.091045</td>\n",
       "      <td>31.612198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>V28</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>-1.227390e-16</td>\n",
       "      <td>0.330083</td>\n",
       "      <td>-15.430084</td>\n",
       "      <td>-0.052960</td>\n",
       "      <td>0.011244</td>\n",
       "      <td>0.078280</td>\n",
       "      <td>33.847808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>8.834962e+01</td>\n",
       "      <td>250.120109</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.600000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>77.165000</td>\n",
       "      <td>25691.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class</th>\n",
       "      <td>284807.0</td>\n",
       "      <td>1.727486e-03</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count          mean           std         min           25%           50%  \\\n",
       "Time    284807.0  9.481386e+04  47488.145955    0.000000  54201.500000  84692.000000   \n",
       "V1      284807.0  1.168375e-15      1.958696  -56.407510     -0.920373      0.018109   \n",
       "V2      284807.0  3.416908e-16      1.651309  -72.715728     -0.598550      0.065486   \n",
       "V3      284807.0 -1.379537e-15      1.516255  -48.325589     -0.890365      0.179846   \n",
       "V4      284807.0  2.074095e-15      1.415869   -5.683171     -0.848640     -0.019847   \n",
       "V5      284807.0  9.604066e-16      1.380247 -113.743307     -0.691597     -0.054336   \n",
       "V6      284807.0  1.487313e-15      1.332271  -26.160506     -0.768296     -0.274187   \n",
       "V7      284807.0 -5.556467e-16      1.237094  -43.557242     -0.554076      0.040103   \n",
       "V8      284807.0  1.213481e-16      1.194353  -73.216718     -0.208630      0.022358   \n",
       "V9      284807.0 -2.406331e-15      1.098632  -13.434066     -0.643098     -0.051429   \n",
       "V10     284807.0  2.239053e-15      1.088850  -24.588262     -0.535426     -0.092917   \n",
       "V11     284807.0  1.673327e-15      1.020713   -4.797473     -0.762494     -0.032757   \n",
       "V12     284807.0 -1.247012e-15      0.999201  -18.683715     -0.405571      0.140033   \n",
       "V13     284807.0  8.190001e-16      0.995274   -5.791881     -0.648539     -0.013568   \n",
       "V14     284807.0  1.207294e-15      0.958596  -19.214325     -0.425574      0.050601   \n",
       "V15     284807.0  4.887456e-15      0.915316   -4.498945     -0.582884      0.048072   \n",
       "V16     284807.0  1.437716e-15      0.876253  -14.129855     -0.468037      0.066413   \n",
       "V17     284807.0 -3.772171e-16      0.849337  -25.162799     -0.483748     -0.065676   \n",
       "V18     284807.0  9.564149e-16      0.838176   -9.498746     -0.498850     -0.003636   \n",
       "V19     284807.0  1.039917e-15      0.814041   -7.213527     -0.456299      0.003735   \n",
       "V20     284807.0  6.406204e-16      0.770925  -54.497720     -0.211721     -0.062481   \n",
       "V21     284807.0  1.654067e-16      0.734524  -34.830382     -0.228395     -0.029450   \n",
       "V22     284807.0 -3.568593e-16      0.725702  -10.933144     -0.542350      0.006782   \n",
       "V23     284807.0  2.578648e-16      0.624460  -44.807735     -0.161846     -0.011193   \n",
       "V24     284807.0  4.473266e-15      0.605647   -2.836627     -0.354586      0.040976   \n",
       "V25     284807.0  5.340915e-16      0.521278  -10.295397     -0.317145      0.016594   \n",
       "V26     284807.0  1.683437e-15      0.482227   -2.604551     -0.326984     -0.052139   \n",
       "V27     284807.0 -3.660091e-16      0.403632  -22.565679     -0.070840      0.001342   \n",
       "V28     284807.0 -1.227390e-16      0.330083  -15.430084     -0.052960      0.011244   \n",
       "Amount  284807.0  8.834962e+01    250.120109    0.000000      5.600000     22.000000   \n",
       "Class   284807.0  1.727486e-03      0.041527    0.000000      0.000000      0.000000   \n",
       "\n",
       "                  75%            max  \n",
       "Time    139320.500000  172792.000000  \n",
       "V1           1.315642       2.454930  \n",
       "V2           0.803724      22.057729  \n",
       "V3           1.027196       9.382558  \n",
       "V4           0.743341      16.875344  \n",
       "V5           0.611926      34.801666  \n",
       "V6           0.398565      73.301626  \n",
       "V7           0.570436     120.589494  \n",
       "V8           0.327346      20.007208  \n",
       "V9           0.597139      15.594995  \n",
       "V10          0.453923      23.745136  \n",
       "V11          0.739593      12.018913  \n",
       "V12          0.618238       7.848392  \n",
       "V13          0.662505       7.126883  \n",
       "V14          0.493150      10.526766  \n",
       "V15          0.648821       8.877742  \n",
       "V16          0.523296      17.315112  \n",
       "V17          0.399675       9.253526  \n",
       "V18          0.500807       5.041069  \n",
       "V19          0.458949       5.591971  \n",
       "V20          0.133041      39.420904  \n",
       "V21          0.186377      27.202839  \n",
       "V22          0.528554      10.503090  \n",
       "V23          0.147642      22.528412  \n",
       "V24          0.439527       4.584549  \n",
       "V25          0.350716       7.519589  \n",
       "V26          0.240952       3.517346  \n",
       "V27          0.091045      31.612198  \n",
       "V28          0.078280      33.847808  \n",
       "Amount      77.165000   25691.160000  \n",
       "Class        0.000000       1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d6a76",
   "metadata": {},
   "source": [
    "**We can see that the data for the variables from V1 to V28 is already scaled and cleaned. So there is no need for a data cleaning process in this case**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618e067",
   "metadata": {},
   "source": [
    "## Response variable analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15cf60d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class\n",
      "Not Fraud    284315\n",
      "Fraud           492\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Fraud vs Non-Fraud\n",
    "class_names = {0: \"Not Fraud\", 1: \"Fraud\"}   ## to improve readability\n",
    "print(df[\"Class\"].value_counts().rename(index = class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f94aa9",
   "metadata": {},
   "source": [
    "* You may notice the **imbalance** in the data labels. \n",
    "* The majority of the transactions are nonfraud. \n",
    "* Due to the imbalance, most models will not place the required emphasis on the fraud signals and the model will assume all the transactions to be nonfraud which would be an unacceptable result. \n",
    "* We shall however learn to handle such issues in subsequent case studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fb2770",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87fb1ca",
   "metadata": {},
   "source": [
    "We can draw the scatterplot matrix and heatmap. Since the variable description is not given in this case, we will not gain any useful insights from the plot. Hence we can skip the step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2516bb",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a1bfdd",
   "metadata": {},
   "source": [
    "This data is already in a cleaned format without any empty rows or columns. Data cleaning or categorization is not required in this case"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20dad91a",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3681ce9b",
   "metadata": {},
   "source": [
    "* Before fitting the data into the machine learning model, we should split the data into training data and testing data. \n",
    "* This is an important step because we would like to train the model by fitting the training data. But to test the data, we should use the data that is new to the model. \n",
    "* Then only we would be able to calculate the performance of the model on the unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7337ecbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d071e0ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df[\"Class\"]\n",
    "X = df.loc[:, df.columns != 'Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e9f3908",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=1/3,random_state=42, stratify=y)      # Stratify parameter ensures that the proportion of values in the training and test data set will be the same as the proportion of values in the master dataset. For example, if variable  is a binary categorical variable with values  and . Suppose there are  of zeros and  of ones, stratify=y will make sure that your random split has  of 0's and  of 1's."
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6f7eefa",
   "metadata": {},
   "source": [
    "df.loc[:, 'column_name']  # Selects all rows for the specified column\n",
    "df.loc['row_label', :]    # Selects all columns for the specified row\n",
    "df.loc['row_label', 'column_name']  # Selects a specific cell by row and column labels"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d425aae",
   "metadata": {},
   "source": [
    "df[:5]   # Selects first 5 rows\n",
    "df[5:]   # Selects all rows from the 6th row onwards\n",
    "df[:5, 'column_name']  # This will raise an error because the slicing operation is not supported for column labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237f1cab",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0dea5b",
   "metadata": {},
   "source": [
    "* In this step we will evaluate different machine learning models.\n",
    "* We will use linear a.w.a. non linear algorithms for this evaluation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd19ad2",
   "metadata": {},
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ece05cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Accuracy Score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de561ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b6952ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Logistic Regression Classifier\n",
    "logisreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a53fd6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using Training Dataset\n",
    "logisreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "958c5f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using test data\n",
    "y_pred = logisreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb86d619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Logistic Regression model :  99.91\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_logisreg = round(accuracy_score(y_test, y_pred)*100, 2)\n",
    "print( 'Accuracy of Logistic Regression model : ', acc_logisreg )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0c158",
   "metadata": {},
   "source": [
    "As data is highly skewed towards non fraud values, thats why see such high accuracy. \n",
    "\n",
    "Skewed data, like in fraud detection where non-fraud cases dominate, can inflate accuracy. For instance, a classifier predicting non-fraud cases with high accuracy might miss detecting actual fraud instances. Therefore, relying solely on accuracy can be misleading. Instead, other metrics like precision, recall, and F1-score should be considered to evaluate performance accurately, especially in imbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec6bbea",
   "metadata": {},
   "source": [
    "**Linear Discriminant Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0766c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Linear Discriminant Analysis\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "71679828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the LDA Classifier\n",
    "model = LinearDiscriminantAnalysis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "751ec6f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearDiscriminantAnalysis()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearDiscriminantAnalysis</label><div class=\"sk-toggleable__content\"><pre>LinearDiscriminantAnalysis()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LinearDiscriminantAnalysis()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6bff82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "75d31d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Linear Discriminant Analysis Classifier:  99.93\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_lda = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of Linear Discriminant Analysis Classifier: ', acc_lda )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cb8386",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "74ea3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Gaussian Naive Bayes\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "45a96c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Gaussian Naive Bayes Classifier\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2224e64c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianNB</label><div class=\"sk-toggleable__content\"><pre>GaussianNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b64e721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "70a7d298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Gaussian Naive Bayes :  99.28\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_ganb = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of Gaussian Naive Bayes : ', acc_ganb )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "190dec9c",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "31a5cdb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e38a506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Decision Tree Classifier\n",
    "model = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3988f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a3ff48dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d5cc5872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Decision Tree Classifier :  99.92\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_dtree = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  Decision Tree Classifier : ', acc_dtree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f16c08",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a8073f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89a0b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Random Forest\n",
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f2a71ad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f81e97fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e1c0fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Random Forest :  99.95\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_rf = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  Random Forest : ', acc_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e601514",
   "metadata": {},
   "source": [
    "**Support Vector Machine Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "de9c0151",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for Support Vector Machine Model\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa9cf752",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the Support Vector Classifier\n",
    "model = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f7475a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "afb9be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "39ee64b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  Support Vector Classifier:  99.83\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_svc = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  Support Vector Classifier: ', acc_svc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd87188",
   "metadata": {},
   "source": [
    "**K Nearest Neighbour Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f9c6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Library for K Nearest Neighbour Model\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c013d29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the K Nearest Neighbour Model with Default Value of K=5\n",
    "model = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e38326be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1180d0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  break\n"
     ]
    }
   ],
   "source": [
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "09ecb5d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  KNN Classifier:  99.83\n"
     ]
    }
   ],
   "source": [
    "# Calculate Model accuracy by comparing y_test and y_pred\n",
    "acc_knn = round( accuracy_score(y_test, y_pred) * 100, 2 )\n",
    "print( 'Accuracy of  KNN Classifier: ', acc_knn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7abe11",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76fbe99",
   "metadata": {},
   "source": [
    "We have no idea which algorithms will do well on this problem. Letâ€™s design our test now. We have used a number of models to fit Y against X. We will evaluate algorithms using the accuracy metric, which is one of the measures of the model performance. We can compare the accuracy of all the models and choose the one with the maximum accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2a934750",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'Linear Discriminant Analysis','Naive Bayes', 'Decision Tree', 'Random Forest', 'Support Vector Machines', \n",
    "              'K - Nearest Neighbors'],\n",
    "    'Score': [acc_logisreg, acc_lda, acc_ganb, acc_dtree, acc_rf, acc_svc, acc_knn]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "047c6cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>99.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linear Discriminant Analysis</td>\n",
       "      <td>99.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>99.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>99.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K - Nearest Neighbors</td>\n",
       "      <td>99.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>99.28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  Score\n",
       "4                 Random Forest  99.95\n",
       "1  Linear Discriminant Analysis  99.93\n",
       "3                 Decision Tree  99.92\n",
       "0           Logistic Regression  99.91\n",
       "5       Support Vector Machines  99.83\n",
       "6         K - Nearest Neighbors  99.83\n",
       "2                   Naive Bayes  99.28"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e1f7de",
   "metadata": {},
   "source": [
    "**We can select the Random Forest as it has given us the maximum accuracy**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b077f94",
   "metadata": {},
   "source": [
    "### Confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc101e",
   "metadata": {},
   "source": [
    "In our project, Random Forest gave the best accuracy. Hence we can analyze the confusion matrix for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadbd0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calculating `y_pred` again using random forest model because `y_pred` values changed as i predicted them later on with diffrenet models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "afc9f332",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\Lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  break\n"
     ]
    }
   ],
   "source": [
    "#Import Library for Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Initialize the Random Forest\n",
    "model = RandomForestClassifier()\n",
    "#Train the model using Training Dataset\n",
    "model.fit(X_train, y_train)\n",
    "# Prediction using test data\n",
    "y_pred = model.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "01871c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[94766,     6],\n",
       "       [   36,   128]], dtype=int64)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f2b0db21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot confusion matrix\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5673395d",
   "metadata": {},
   "source": [
    "* In this case, overall accuracy is strong, but the confusion metrics tell a different story. \n",
    "* Despite the high accuracy level, 36 out of 164 instances of fraud are missed and incorrectly predicted as nonfraud. \n",
    "* The false-negative rate is substantial. The intention of a fraud detection model is to minimize these false negatives.\n",
    "* Therefore, in the context of fraud detection, where minimizing false negatives is crucial to prevent financial losses, recall is typically prioritized over precision or accuracy to determine the performance of the models.\n",
    "  {{However, it's essential to consider the trade-off between recall and precision based on the specific requirements and constraints of the application.}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0d46e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
